{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97dbfe74",
   "metadata": {},
   "source": [
    "# Word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52efc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'semantic':[ 0.00609409 -0.04229162 -0.04111972 -0.00115508  0.00618644 -0.0287169\n",
      " -0.02362637 -0.03673037  0.04164308  0.00060649 -0.022547    0.02850853\n",
      "  0.04590008 -0.02049936  0.03982341  0.02687717  0.02939562  0.00256295\n",
      "  0.04106542 -0.0350952 ]\n",
      "====================================================================================================\n",
      "Vector for 'nlp':[-0.04309844  0.01832869  0.02594942  0.02870969  0.03733459 -0.03083838\n",
      "  0.00552807  0.03023641 -0.01420025 -0.03086761 -0.00205112 -0.04184474\n",
      " -0.02800006  0.03552269  0.0167627   0.03612835  0.03400124  0.03765371\n",
      " -0.01894577 -0.00280903]\n",
      "====================================================================================================\n",
      "Similarity b/w 'word' and 'embeddings':0.07046514004468918\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#sample text\n",
    "text=['Word embeddings capture semantic relationships.',\n",
    " 'Word2vec is a popular technique in nlp',\n",
    " 'Word embedding model in a continuos vector space']\n",
    "tokenized_text=[word_tokenize(sentence.lower()) for sentence in text]\n",
    "#Train Word2vec model\n",
    "model=Word2Vec(sentences=tokenized_text,vector_size=20,window=5,min_count=1,workers=4)\n",
    "#Find word vectors\n",
    "vector_semantic=model.wv['semantic']\n",
    "vector_nlp=model.wv['nlp']\n",
    "#similarity b/w words\n",
    "similarity=model.wv.similarity('word','embeddings')\n",
    "print(f\"Vector for 'semantic':{vector_semantic}\")\n",
    "print('='*100)\n",
    "print(f\"Vector for 'nlp':{vector_nlp}\")\n",
    "print('='*100)\n",
    "print(f\"Similarity b/w 'word' and 'embeddings':{similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a0e7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b641117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
